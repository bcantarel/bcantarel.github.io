<!doctype html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Unix Review</title>
  <meta name="description" content="Nano Courses"/>
  <meta name="keywords" content=""/>
  <meta name="robots" content=""/>
  <link rel="canonical" href=""/>
  
  
  <meta name="HandheldFriendly" content="True"/>
  <meta name="MobileOptimized" content="320"/>
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <style media="screen" type="text/css">
    li{
    margin: 10px 0;
    }
  </style>

   <body>
     <h1> 2016 NGS Summer BootCamp: Metagenomics Workshop</h1>
     <p>
       This exercise is adapted from the Mothur MiSeq SOP<br>
       http://www.mothur.org/wiki/MiSeq_SOP<br>
     <p>
       <i>Kozich JJ, Westcott SL, Baxter NT, Highlander SK, Schloss PD. (2013): Development of a dual-index sequencing strategy and curation pipeline for analyzing amplicon sequence data on the MiSeq Illumina sequencing platform. Applied and Environmental Microbiology. 79(17):5112-20.</i><br>
<p>
<h3>Start Mothur</h3>
First let’s set up your environment:<br>
<code>
ln -s /data/bootcamp/day2/* .<br>
qrsh<br>
cd day2<br>
/data/bootcamp/seqprg/mothur/mothur<br>
</code>
<p>
<h3>Reducing sequencing and PCR errors</h3>
<p>
In this exercise we are going to examine the microbiome from the pig intestinal track from one donor.  These sequences were generated by 454 downloaded from SRA.<br>
<p>
<i>Looft T, Allen HK, Cantarel BL, Levine UY, Bayles DO, Alt DP, Henrissat B, Stanton TB. Bacteria, phages and pigs: the effects of in-feed antibiotics on the  microbiome at different gut locations. ISME J. 2014 Aug;8(8):1566-76. doi: 10.1038/ismej.2014.12. Epub 2014 Feb 13. PubMed PMID: 24522263.</i><br>
<p>
<h4>First let's examine the sequence data</h4>
<p>
<code>
summary.seqs(fasta=swine_gut.fasta)<br>
</code>
<p>
Now lets trim sequences based on quality, remove any large, small, ambiguious or reads with lots of homopolymers<br>
<p>
<code>
trim.seqs(fasta=swine_gut.fasta,qfile=swine_gut.qual,qaverage=25,maxambig=0,maxhomop=8,minlength=200,maxlength=800,processors=2)<br>
</code>
<p>
Now we are going to reduce the number of reads for analysis. Don’t worry we are “keeping” these sequences for abundance purposes, just not for analysis.<br>
<p>
<code>
unique.seqs(fasta=swine_gut.trim.fasta)<br>
</code>
<p>
<h4>Processing improved sequences</h4>
<p>
Normally, we can limit the alignment to the variable region of the 16S gene based on the primers.  First thing we would do is to reduce the 16S reference alignment to this region.  But this step is very long, so we are going to use the precut alignment.<br>
<p>
<code>
#pcr.seqs(fasta=silva.nr_v119.align, start=1044, end=6500,keepdots=F)<br>
</code>
<p>
Next align sequences to template 16S rRNA gene.  We can remove any sequences that don’t align to the expected PCR region.   The alignment step can also be very long – so you should probably skip this step too.<br>
<p>
<code>
#align.seqs(fasta=swine_gut.trim.unique.fasta,template=silva.nr_v119.pcr.align,flip=t,processors=2)<br>
</code>
<p>
<h4>Summarize results so far</h4>
<p>
<code>
summary.seqs(fasta=swine_gut.trim.unique.align, name=swine_gut.trim.names)<br>
</code>
<p>
Next we want to create a file to keep track of the count of our representative sequences in each sample.  Since we skipped some the demultiplexing steps, well have to generate the read to same file (group file).  Then create a count table.
<p>
<code>
system(perl make_group_names.pl swine_gut.trim.names)<br>
count.seqs(name=swine_gut.trim.names, group=swine_gut.trim.groups)<br>
</code>
<p>
Now we want to “clean” up our alignment, determine the sequences that cover most of the PCR region, cut the alignment to that region and remove those that don’t span the whole region<br>
<p>
<code>
screen.seqs(fasta=swine_gut.trim.unique.align, count=swine_gut.trim.count_table,start=2,optimize=end, criteria=85, processors=2)<br>
filter.seqs(fasta=swine_gut.trim.unique.good.align, vertical=T, trump=., processors=2)<br>
</code>
<p>
Now that our alignment is of high quality, let’s remove redundant sequences and cluster sequences with only 2 mismatches (these could represent sequencing errors)
<p>
<code>
unique.seqs(fasta=swine_gut.trim.unique.good.filter.fasta, count=swine_gut.trim.good.count_table)<br>
pre.cluster(fasta=swine_gut.trim.unique.good.filter.unique.fasta,count=swine_gut.trim.unique.good.filter.count_table,diffs=2)<br>
</code>
<p>
We want to identify and remove chimera sequences.  This step is really slow, we have already identified these sequences.  So skip this step and remove the chimeras.
<p>
<code>
#chimera.uchime(fasta=swine_gut.trim.unique.good.filter.unique.precluster.fasta, reference=silva.gold.align,processors=3) remove.seqs(accnos=swine_gut.trim.unique.good.filter.unique.precluster.ref.uchime.accnos, fasta=swine_gut.trim.unique.good.filter.unique.precluster.fasta,count=swine_gut.trim.unique.good.filter.unique.precluster.count_table)<br>
</code>
<p>
<h4>Taxonomic Classification</h4>
<br>
#Classify Sequences into Taxonomic Bins<br>
<p>
<code>
classify.seqs(fasta=swine_gut.trim.unique.good.filter.unique.precluster.pick.fasta, template=silva.nr_v119.pcr.align, taxonomy=silva.nr_v119.tax, cutoff=50, processors=2)<br>
</code>
<p>
This command allows you to remove suspicious sequences, for example if you suspect Cyanobacteria as representing chloroplast from plant material (which it could in the gut), you can remove it <br>
<p>
<code>
remove.lineage(fasta=swine_gut.trim.unique.good.filter.unique.precluster.pick.fasta, count=swine_gut.trim.unique.good.filter.unique.precluster.pick.count_table, taxonomy=swine_gut.trim.unique.good.filter.unique.precluster.pick.nr_v119.wang.taxonomy,taxon=Cyanobacteria)<br>
</code>
<p>
#mothur has a tendency to make long complicated names, these commands allows you to rename files to shorter names<br>
<p>
<code>
system(cp swine_gut.trim.unique.good.filter.unique.precluster.pick.pick.fasta final.fasta)<br>
system(cp swine_gut.trim.unique.good.filter.unique.precluster.pick.pick.count_table final.count_table)<br>
system(cp swine_gut.trim.unique.good.filter.unique.precluster.pick.nr_v119.wang.pick.taxonomy final.taxonomy)<br>
</code>
<p>
<h4>Preparing for OTU analysis</h4>
<p>
Create a distance matrix comparing 16S sequences in your samples.  Then cluster sequences into OTU -- we are using the command cluster.split to do that as it allows us to cluster sequences according a taxonomic level like order or family
<p>
<code>
dist.seqs(fasta=final.fasta,cutoff=0.15, processors=2)<br>
cluster.split(column=final.dist, taxonomy=final.taxonomy, count=final.count_table, splitmethod=classify, taxlevel=4, processors=1)
</code>
<p>
To know the taxonomy for each of our OTUs, get the consensus taxonomy for each OTU
<p>
<code>
classify.otu(list=final.an.unique_list.list, count=final.count_table, taxonomy=final.taxonomy, label=0.03)
</code>
<p>
#Calculate the relative abundance of taxa<br>
#The number of sequences in your count table should match the number in your OTU list file, therefore you have to fix the count file<br>
<p>
<code>
phylotype(taxonomy=final.taxonomy,count=final.count_table)<br>
system(perl fix_ct.pl)
</code>
<p>

<p>
<h4>Analysis</h4>
<p>
#Generates collector's curves<br>
#The make.shared creates a file that represent the number of times that an OTU is observed in multiple samples
<p>
<code>
make.shared(list=final.an.unique_list.list,count=final.fix.count_table, label=0.03)
</code>
<p>
Let's start our analysis by analyzing the alpha diversity of the samples. First we will generate collector's curve of the Chao1 richness estimators and the inverse Simpson diversity index.
<p>
<code>
collect.single(shared=final.an.unique_list.shared, calc=chao-invsimpson, freq=100)
</code>
<p>
This command will generate file ending in *.chao and *.invsimpson for each sample, which can be plotted in your favorite graphing software package. It is important to point out that Chao1 is really a measure of the minimum richness in a community, not the full richness of the community. Also, there isn't much to do with these plots since it's based on a single sampling. One method often used to get around this problem is to look at rarefaction curves describing the number of OTUs observed as a function of sampling effort.
<p>
<code>
rarefaction.single(shared=final.an.unique_list.shared, calc=sobs, freq=100)
</code>
<p>
#Determine the sequence count per sample<br>
<code>
count.groups(shared=final.an.unique_list.shared)
</code>
<p>
This will generate files ending in *.rarefaction, which again can be plotted in your favorite graphing software package. Alas, rarefaction is not a measure of richness, but a measure of diversity. If you consider two communities with the same richness, but different evenness then after sampling a large number of individuals their rarefaction curves will asymptote to the same value. Since they have different evennesses the shapes of the curves will differ. Therefore, selecting a number of individuals to cutoff the rarefaction curve isn't allowing a researcher to compare samples based on richness, but their diversity. Finally, let's get a table containing the number of sequences, the sample coverage, the number of observed OTUs, and the Inverse Simpson diversity estimate using the summary.single command. To standardize everything, let's randomly select sequences from each sample 1000 times and calculate the average (note: that if we set subsample=T, then it would use the size of the smallest library):
<p>
<code>
summary.single(shared=final.an.unique_list.shared, calc=nseqs-coverage-sobs-invsimpson, subsample=2725)
</code>
<p>
Subsample the OTUs using the minimum number of sequences.  Then, let’s determine whether  our data can be partintioned in to separate community types.
<p>
<code>
sub.sample(shared=final.an.unique_list.shared, size=2725)<br>
get.communitytype(shared=final.an.unique_list.0.03.subsample.shared)
</code>
<p>
The unifrac-based metrics are used to assess the similarity between two communities membership (unifrac.unweighted) and structure (unifrac.weighted). We will use these metrics and generate PCoA plots to compare our samples. There are two beta-diversity metrics that one can use - unweighted and weighted. We will also have mothur subsample the trees 1000 times and report the average.  In order to do unifract analysis (beta diversity), we need to determine the distances between sequences, build a phylogentic tree and then compare samples using unifract.  Principal Coordinates (PCoA) uses an eigenvector-based approach to represent multidimensional data in as few dimesnsions as possible. Our data is highly dimensional (~9 dimensions).  Tree building is a very slow step.  Please use the pre-generated tree.
<p>
<code>
#dist.seqs(fasta=final.fasta,cutoff=0.15, output=lt,processors=4)<br>
#clearcut(phylip=final.phylip.dist)<br>
unifrac.unweighted(tree=final.phylip.tre, count=final.count_table, distance=lt, processors=2, random=F, subsample=2725)<br>
unifrac.weighted(tree=final.phylip.tre, count=final.count_table, distance=lt, processors=2, random=F, subsample=2725)<br>
pcoa(phylip=final.phylip.1.unweighted.ave.dist)<br>
pcoa(phylip=final.phylip.tre1.weighted.ave.dist)
</code>
<p>
We can do the same analysis using the similarity of the membership and structure found in the various samples
<p>
<code>
dist.shared(shared=final.an.unique_list.shared, calc=thetayc-jclass, subsample=2725)<br>
pcoa(phylip=final.an.unique_list.thetayc.0.03.lt.dist)<br>
nmds(phylip=final.an.unique_list.thetayc.0.03.lt.dist)
</code>
<p>
Finally, no microbiome study would be complete without a few heatmaps.  We can visualize those distances as similarities in a heatmap with the Jaccard and thetayc coefficients.  We can also visualize relative abundance of each OTU across the 24 samples using the heatmap.bin command and log2 scaling the relative abundance values. Because there are so many OTUs, let's just look at the top 50 OTUs.
<p>
<code>
heatmap.bin(shared=final.an.unique_list.shared, scale=log2, numotu=50) <br>
heatmap.sim(phylip=final.an.unique_list.thetayc.0.03.lt.dist)<br>
heatmap.sim(phylip=final.an.unique_list.jclass.0.03.lt.dist)
</code>
<p>
<h4>Create a file that you can import into MEGAN:</h4>
<code>
make.biom(shared=final.an.unique_list.0.03.subsample.shared,constaxonomy=final.an.unique_list.0.03.cons.taxonomy)
</code>
<p>
Now you want to download some data to your local machine:<br>
Open a new tab on your terminal
<p>
<code>
mkdir metagenomic_workshops<br>
cd metagenomic_workshops<br>
scp username@toxea.swmed.edu:~/day2/\*.biome .<br>
scp username@toxea.swmed.edu:/data/bootcamp/day2/\*.rma .<br>
scp username@toxea.swmed.edu:~/day2/\*.svg .<br>
scp username@toxea.swmed.edu:~/day2/\*.axes\* .<br>
scp username@toxea.swmed.edu:~/day2/\*.invsimpson .<br>
scp username@toxea.swmed.edu:~/day2/\*.rarefaction .<br>
</code>
</html>
